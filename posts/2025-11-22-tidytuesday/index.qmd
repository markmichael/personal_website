
---
title: "TidyTuesday 2025-11-18 - Sherlock Holmes"
date: "2025-11-22"
categories: ["data science", "tidytuesday", "rstats"]
---

## The Complete Works of Sherlock Holmes

TidyTuesday is weekly data visualization challenge. The details for this week can be found [here](https://github.com/rfordatascience/tidytuesday/tree/main/data/2025/2025-11-18).

### Introduction


```{r setup1, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(gt)
```

```{r setup2, include=FALSE}
data <- tidytuesdayR::tt_load("2025-11-18")[[1]]

```


Analysing literature with data science and numerical methods is a fun journey. A few years ago I read [Nabokov's favorite word is mauve](https://www.goodreads.com/book/show/30753786-nabokov-s-favorite-word-is-mauve) by Ben Blatt. The methods for quantifying literature are both interesting and compelling, and I'm interested in seeing if there are similar patterns here. Sidenote: that book was described to me as "the most NPR book ever," and I love that.

My first step is to explore samples of the data to see if it's usable as is.

```{r}

books <- data |>
  distinct(book) |>
  mutate(publish_order = row_number())



text_sample <- data[2000:2100,]

text_sample |>
  gt() |>
  tab_header(title = "Sample of Text") |>
  opt_stylize(style = 6, color = "gray") |>
  tab_options(container.height = "300px", container.overflow.y = "scroll")

```

The most remarkable thing from the sample is that each observation represents a literal line in the novel. The lines can be concatenated so that each observation is a paragraph. This will be particularly useful in understanding dialog because it is typical in literature to start a new paragraph each time a speaker changes. The NAs between lines mean we have a good boundary between paragraphs.

Additionally, I cross-referenced the novel order with the [Canon of Sherlock Holmes](https://en.wikipedia.org/wiki/Canon_of_Sherlock_Holmes) in order to understand the order in which these works were published. I think it could be interesting to see if there are changes that occur between earlier works and later works.

```{r}

paragraphs <- data |>
  mutate(paragraph = cumsum(is.na(text))) |>
  filter(!is.na(text)) |>
  group_by(book,paragraph) |>
  summarize(text = paste(text, collapse = " "))

paragraphs_sample <- paragraphs[2000:2010,]

paragraphs_sample |>
  gt() |>
  tab_header(title = "Sample of Paragraphs") |>
  opt_stylize(style = 6, color = "gray") |>
  tab_options(container.height = "300px", container.overflow.y = "scroll")

```

### Exclamation points 

F. Scott Fitzgerald and Earnest Hemingway were known for their very resvered use of exclamation points. Fizgerald describes it as "Laughing at your own joke." We can use this data to determine how well Arthur Conan Doyle follows this rule.

```{r}

exclamation_points <- paragraphs |>
  mutate(exclamation_points = str_count(text, "!"))

exclamation_point_sample <- exclamation_points |>
  filter(exclamation_points > 0) |>
  ungroup() |>
  slice_sample(n = 5)

### showing some example lines as a sanity check to make sure our code is working

exclamation_point_sample |>
  gt() |>
  tab_header(title = "Sample of Lines with Exclamation Points") |>
  opt_stylize(style = 6, color = "gray") |>
  tab_options(container.height = "300px", container.overflow.y = "scroll")

exclamation_points_summary <- exclamation_points |>
  group_by(book) |>
  summarize(exclamation_points = sum(exclamation_points)) |>
  left_join(books, by = "book") |>
  arrange(publish_order)

### actually counting exclamation points

exclamation_points_summary |>
  gt() |>
  tab_header(title = "Exclamation Points per Book") |>
  tab_options(container.height = "500px", container.overflow.y = "scroll") |>
  cols_label(
    book = "Book",
    exclamation_points = "Exclamation Points",
    publish_order = "Publish Order"
  ) |>
  fmt_number(columns = exclamation_points, decimals = 0)
```

Noteably the 4 highest counts are full novels, while the rest are short stories. It makes sense that they are higher, but they will skew the rest of the analysis.

In graphical form:

```{r}

novels <- c("A Study In Scarlet",
            "The Sign of the Four",
            "The Hound of the Baskervilles",
            "The Valley Of Fear" )

exclamation_points_summary |>
  filter(!(book %in% novels)) |>
  ggplot(aes(x = publish_order, y = exclamation_points)) +
  geom_point() +
  geom_smooth(method = "lm") +
  labs(
    x = "Publish Order",
    y = "Exclamation Points",
    title = "Exclamation Points per Book"
  )
```

Graphically, it does not look like Doyle's use of exclamation points changed over time. We can verify this mathematically.

```{r}

exclamation_points_summary |>
  filter(!(book %in% novels)) |>
  lm(exclamation_points ~ publish_order, data = _) |>
  summary()

```

### Matrix Profile Analysis

The [Matrix Profile](https://www.cs.ucr.edu/~eamonn/MatrixProfile.html) is a mathematical method used for finding motifs, discords, and other insights in time series data. Text can be transformed into time series data by converting each letter into a number and using the index for time.

```{r}
# Concatenate all text for each book
book_text <- paragraphs |>
  group_by(book) |>
  summarize(text = paste(text, collapse = " "))

# Function to convert text to a numerical sequence
text_to_numeric <- function(text) {
  # Convert to lowercase
  text <- tolower(text)
  # Split into characters
  chars <- strsplit(text, "")[[1]]
  # Convert characters to numbers
  sapply(chars, function(char) {
    utf8ToInt(char) 
  })
}

# Apply the function to each book's text
numerical_text <- book_text |>
  mutate(numeric_representation = map(text, text_to_numeric))

# Display a sample of the numerical representation
numerical_text |>
  mutate(numeric_sample = map_chr(numeric_representation, ~ paste(head(.x, 20), collapse = ", "))) |>
  mutate(text_sample = map_chr(numeric_representation, ~intToUtf8(head(.x, 20)))) |>
  select(book, text_sample, numeric_sample) |>
  slice_sample(n = 5) |>
  gt() |>
  tab_header(title = "Numerical Representation of Book Text (First 20 Characters)") |>
  cols_label(
    book = "Book",
    text_sample = "Text Sample",
    numeric_sample = "Numerical Sequence"
  )
```

Next, we can apply the matrix profile. The only parameter input required is the size of a subsequence to use in our search. I'm going to follow classic Twitter's paradigm and us a character length of 140.

```{r}

book1 <- numerical_text |>
  filter(book == "The Sign of the Four") |>
  pull(numeric_representation)

mp <- tsmp::scrimp(book1, 140)

```
