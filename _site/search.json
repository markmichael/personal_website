[
  {
    "objectID": "posts/2025-11-15-from_the_furrows/index.html",
    "href": "posts/2025-11-15-from_the_furrows/index.html",
    "title": "From the Furrows - building a grownup backend",
    "section": "",
    "text": "Over a year ago, I committed my first lines of code for our new app. At that point I had used R for advanced data analysis work and dabbled into building my first applications. Armed with that and some product knowledge building health apps. Peter and I started on our Harvvest journey. We started assembling a list of brands with affiliate links and I created my first endpoint using plumber to show that list to the client.\nNow our app has become more complex. Users can preview brand deals to promote, generate their unique links, receive brand kits for the deals they want to promote, and track and withdraw their earnings. We brought on a more experienced backend developer and have started building the next version of our app, informed by the challenges from the previous year. One of the particularly interesting things about this type of growth is that some of the decisions that we are now considering suboptimal were actually pretty good for when we were getting started. And some of them were just bad. I’m going to go through some of those considerations here. \n\n\n\nPeter and I over a year into Harvvest with our first company swag\n\n\n\nWriting a backend in R\nThere is a lot of commentary for and against R in production environments. This article provides an excellent technical discussion on the topic. For an application like Harvvest, languages more tailored towards performance and concurrency rather than statistics would have been better. That said, it was the language I knew best. And because I had that knowledge, I could focus more on the programming methodology rather than banging my head against tons of syntax errors and blindly copying code for ChatGPT or StackOverflow. In fact, as we are transitioning to Python and FastAPI, we’re finding that probably around 85% of the endpoints and general functionality will be conserved. Also, I was able to build faster. When we planned for a new feature, I would typically have the backend and documentation completed within a day. Overall, I was happy with this choice in the beginning, and I think we still could have gotten more mileage from our R backend.\nI did do a couple of important changes along the way to account for some of R’s shortcomings. The first was that for some functionality, like sending a welcome email, it made sense to do it with a database function instead of via the backend. Accounts were created through direct interface with Supabase, so the database would know before the backend knew that an account had been created. Another change was that I moved functionality related to followers to a separate service written in Elixir. Our app would primarily be used by influencers. Their followers, who probably outnumber influencers by at least an order of magnitude, interact with the links that the influencers generate and post. With that change, our linking service was able to support our highest traffic days.\n\n\nDatabases\nMy background with databases until this point had been almost entirely querying data with SQL and working with it in R. I had never created tables or stored data in a database before. We made the decision to use Google Cloud because I had burned through my AWS free trials on a previous project. The natural option then became Firebase’s NoSQL database. Not only was I not familiar with interfacing with these types of databases, but I also could not find a mature R package to abstract the nuances away. I got to the point where I was using httr2 to populate brand deals into the Firebase before deciding that this process was not sustainable and I need to switch to something I was more familiar with–Postgres.\nI ended up choosing Supabase without really understanding all the implications of that decision. Fortunately, it had benefits that I did not realize as I was making the decision. User creation and authentication are automatically taken care of, social logins were much easier to implement, and security was largely handled for me. Additionally, their free tier is plenty to prove out an idea.\nAn important lesson I learned is that using R to interface with a database for data analysis and data science vs building a consumer application. Querying data using dbplyr is fantastic, but R does a lot of magic behind the scenes in the form of type changing. Enums and uuids both get changed to strings. And you don’t need to do anything with foreign keys to link your tables together–you just know which columns you want to join by and join them. This resulted in the schema visualizer showing each table in a vertical line with no relationships between them. It also was incorrectly forgiving when saving values that had inconsistent capitalization or other subtle differences.\n\n\nCI/CD\nFor some of my earlier projects, my deployments involved building a docker image, pushing it to Docker Hub, then SSHing into my ec2 instance on AWS, and then pulling and running the container. For Harvvest, we switched to GCP and I used Cloud Run and Cloud Build. Both of these made it very easy for me to build and deploy just by merging a pull request on Github. I had encountered a few cases where my local testing using docker compose would behave differently than the cloud deployment. Sometimes it was related to resources available to the container. Several times, I forgot to add new environment variables. One of the most frustrating was that Cloud Run had a harder time executing a complex initial command, such as importing my libraries and starting Plumber. For that I created an init.R file with all the setup commands an then used a simple Rscript init.R in my Dockerfile.\nWith my setup, building and deploying from Github was the only thing I knew how to do. A downside to this was that I was building separate containers for dev and production. For our new pipeline we are going to switch to only building the dev app, and then re-deploying that image in production when testing is complete. Additionally, we have done very little with testing via Github actions and are planning to incorporate more of that to help us feel more confident in our releases."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "mark michael",
    "section": "",
    "text": "TidyTuesday 2025-11-18 - Sherlock Holmes\n\n\n\ndata science\n\ntidytuesday\n\nrstats\n\n\n\n\n\n\n\n\n\nNov 22, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nFrom the Furrows - building a grownup backend\n\n\n\ndevelopment\n\nharvvest\n\n\n\n\n\n\n\n\n\nNov 15, 2025\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Hi, I’m Mark. I’m a Seattle-baed product manager with a background in medicine. I have opinions about healthcare, technology, cycling, and other things.   Most recently, I’ve been building Harvvest, a platform that helps influencers monetize their content by connecting them with brands for them to promote.  \nMD - Baylor College of Medicine  BE Biomedical Engineering - Vanderbilt University"
  },
  {
    "objectID": "posts/2025-11-22-tidytuesday/index.html",
    "href": "posts/2025-11-22-tidytuesday/index.html",
    "title": "TidyTuesday 2025-11-18 - Sherlock Holmes",
    "section": "",
    "text": "Analysing literature with data science and numerical methods is a fun journey. A few years ago I read Nabokov’s favorite word is mauve by Ben Blatt. The methods for quantifying literature are both interesting and compelling, and I’m interested in seeing if there are similar patterns here. Sidenote: that book was described to me as “the most NPR book ever,” and I love that.\nMy first step is to explore samples of the data to see if it’s usable as is.\n\nbooks &lt;- data |&gt;\n  distinct(book) |&gt;\n  mutate(publish_order = row_number())\nprint(books)\n\n# A tibble: 48 × 2\n   book                                publish_order\n   &lt;chr&gt;                                       &lt;int&gt;\n 1 A Study In Scarlet                              1\n 2 The Sign of the Four                            2\n 3 A Scandal in Bohemia                            3\n 4 The Red-Headed League                           4\n 5 A Case of Identity                              5\n 6 The Boscombe Valley Mystery                     6\n 7 The Five Orange Pips                            7\n 8 The Man with the Twisted Lip                    8\n 9 The Adventure of the Blue Carbuncle             9\n10 The Adventure of the Speckled Band             10\n# ℹ 38 more rows\n\ntext_sample &lt;- data[2000:2100,]\n\nprint(text_sample)\n\n# A tibble: 101 × 3\n   book               text                                              line_num\n   &lt;chr&gt;              &lt;chr&gt;                                                &lt;dbl&gt;\n 1 A Study In Scarlet \"\\\"'You had best tell me all about it now,' I sa…     2000\n 2 A Study In Scarlet \"are worse than none. Besides, you do not know h…     2001\n 3 A Study In Scarlet \"it.'\"                                                2002\n 4 A Study In Scarlet  &lt;NA&gt;                                                 2003\n 5 A Study In Scarlet \"\\\"'On your head be it, Alice!' cried her mother…     2004\n 6 A Study In Scarlet \"me, 'I will tell you all, sir. Do not imagine t…     2005\n 7 A Study In Scarlet \"behalf of my son arises from any fear lest he s…     2006\n 8 A Study In Scarlet \"in this terrible affair. He is utterly innocent…     2007\n 9 A Study In Scarlet \"however, that in your eyes and in the eyes of o…     2008\n10 A Study In Scarlet \"be compromised. That however is surely impossib…     2009\n# ℹ 91 more rows\n\n\nThe most remarkable thing from the sample is that each observation represents a literal line in the novel. The lines can be concatenated so that each observation is a paragraph. This will be particularly useful in understanding dialog because it is typical in literature to start a new paragraph each time a speaker changes. The NAs between lines mean we have a good boundary between paragraphs.\nAdditionally, I cross-referenced the novel order with the Canon of Sherlock Holmes in order to understand the order in which these works were published. I think it could be interesting to see if there are changes that occur between earlier works and later works.\n\nparagraphs &lt;- data |&gt;\n  mutate(paragraph = cumsum(is.na(text))) |&gt;\n  filter(!is.na(text)) |&gt;\n  group_by(book,paragraph) |&gt;\n  summarize(text = paste(text, collapse = \" \"))\n\n`summarise()` has grouped output by 'book'. You can override using the\n`.groups` argument.\n\nparagraphs_sample &lt;- paragraphs[2000:2010,]\n\nprint(paragraphs_sample)\n\n# A tibble: 11 × 3\n# Groups:   book [1]\n   book                                        paragraph text                   \n   &lt;chr&gt;                                           &lt;int&gt; &lt;chr&gt;                  \n 1 The Adventure of Charles Augustus Milverton      7455 \"\\\"What I say is true,…\n 2 The Adventure of Charles Augustus Milverton      7456 \"\\\"There you make a mi…\n 3 The Adventure of Charles Augustus Milverton      7457 \"Holmes sprang from hi…\n 4 The Adventure of Charles Augustus Milverton      7458 \"\\\"Get behind him, Wat…\n 5 The Adventure of Charles Augustus Milverton      7459 \"Milverton had glided …\n 6 The Adventure of Charles Augustus Milverton      7460 \"\\\"Mr. Holmes, Mr. Hol…\n 7 The Adventure of Charles Augustus Milverton      7461 \"Holmes sat motionless…\n 8 The Adventure of Charles Augustus Milverton      7462 \"For some days Holmes …\n 9 The Adventure of Charles Augustus Milverton      7463 \"\\\"You would not call …\n10 The Adventure of Charles Augustus Milverton      7464 \"\\\"No, indeed!\\\"\"      \n11 The Adventure of Charles Augustus Milverton      7465 \"\\\"You'll be intereste…\n\n\n\n\n\nF. Scott Fitzgerald and Earnest Hemingway were known for their very resvered use of exclamation points. Fizgerald describes it as “Laughing at your own joke.” We can use this data to determine how well Arthur Conan Doyle follows this rule.\n\nexclamation_points &lt;- paragraphs |&gt;\n  mutate(exclamation_points = str_count(text, \"!\"))\n\nexclamation_point_sample &lt;- exclamation_points |&gt;\n  filter(exclamation_points &gt; 0) |&gt;\n  slice_sample(n = 5)\n\n### showing some example lines as a sanity check to make sure our code is working\n\nprint(exclamation_point_sample)\n\n# A tibble: 240 × 4\n# Groups:   book [48]\n   book                 paragraph text                        exclamation_points\n   &lt;chr&gt;                    &lt;int&gt; &lt;chr&gt;                                    &lt;int&gt;\n 1 A Case of Identity        2195 \"\\\"Certainly,\\\" said Holme…                  1\n 2 A Case of Identity        2131 \"\\\"Ha! that was unfortunat…                  1\n 3 A Case of Identity        2197 \"\\\"Oh, it won't do--really…                  1\n 4 A Case of Identity        2207 \"\\\"There's a cold-blooded …                  1\n 5 A Case of Identity        2196 \"\\\"What! where?\\\" shouted …                  1\n 6 A Scandal in Bohemia      1847 \"\\\"What a woman--oh, what …                  1\n 7 A Scandal in Bohemia      1671 \"\\\"Pooh, pooh! Forgery.\\\"\"                   1\n 8 A Scandal in Bohemia      1754 \"\\\"Oh, the cause is excell…                  1\n 9 A Scandal in Bohemia      1829 \"\\\"Married! When?\\\"\"                         1\n10 A Scandal in Bohemia      1621 \"\\\"Quite so! You have not …                  1\n# ℹ 230 more rows\n\nexclamation_points_summary &lt;- exclamation_points |&gt;\n  group_by(book) |&gt;\n  summarize(exclamation_points = sum(exclamation_points)) |&gt;\n  left_join(books, by = \"book\") |&gt;\n  arrange(desc(exclamation_points))\n\n### actually counting exclamation points\n\nprint(exclamation_points_summary)\n\n# A tibble: 48 × 3\n   book                                        exclamation_points publish_order\n   &lt;chr&gt;                                                    &lt;int&gt;         &lt;int&gt;\n 1 The Valley Of Fear                                         319            40\n 2 The Hound of the Baskervilles                              182            39\n 3 The Sign of the Four                                       127             2\n 4 A Study In Scarlet                                          85             1\n 5 The Adventure of the Second Stain                           49            38\n 6 The Adventure of the Solitary Cyclist                       48            29\n 7 The Adventure of the Red Circle                             46            43\n 8 The Adventure of the Dying Detective                        45            45\n 9 The Adventure of the Beryl Coronet                          43            13\n10 The Adventure of the Bruce-Partington Plans                 43            44\n# ℹ 38 more rows"
  },
  {
    "objectID": "posts/2025-11-22-tidytuesday/index.html#the-complete-works-of-sherlock-holmes",
    "href": "posts/2025-11-22-tidytuesday/index.html#the-complete-works-of-sherlock-holmes",
    "title": "TidyTuesday 2025-11-18 - Sherlock Holmes",
    "section": "",
    "text": "Analysing literature with data science and numerical methods is a fun journey. A few years ago I read Nabokov’s favorite word is mauve by Ben Blatt. The methods for quantifying literature are both interesting and compelling, and I’m interested in seeing if there are similar patterns here. Sidenote: that book was described to me as “the most NPR book ever,” and I love that.\nMy first step is to explore samples of the data to see if it’s usable as is.\n\nbooks &lt;- data |&gt;\n  distinct(book) |&gt;\n  mutate(publish_order = row_number())\nprint(books)\n\n# A tibble: 48 × 2\n   book                                publish_order\n   &lt;chr&gt;                                       &lt;int&gt;\n 1 A Study In Scarlet                              1\n 2 The Sign of the Four                            2\n 3 A Scandal in Bohemia                            3\n 4 The Red-Headed League                           4\n 5 A Case of Identity                              5\n 6 The Boscombe Valley Mystery                     6\n 7 The Five Orange Pips                            7\n 8 The Man with the Twisted Lip                    8\n 9 The Adventure of the Blue Carbuncle             9\n10 The Adventure of the Speckled Band             10\n# ℹ 38 more rows\n\ntext_sample &lt;- data[2000:2100,]\n\nprint(text_sample)\n\n# A tibble: 101 × 3\n   book               text                                              line_num\n   &lt;chr&gt;              &lt;chr&gt;                                                &lt;dbl&gt;\n 1 A Study In Scarlet \"\\\"'You had best tell me all about it now,' I sa…     2000\n 2 A Study In Scarlet \"are worse than none. Besides, you do not know h…     2001\n 3 A Study In Scarlet \"it.'\"                                                2002\n 4 A Study In Scarlet  &lt;NA&gt;                                                 2003\n 5 A Study In Scarlet \"\\\"'On your head be it, Alice!' cried her mother…     2004\n 6 A Study In Scarlet \"me, 'I will tell you all, sir. Do not imagine t…     2005\n 7 A Study In Scarlet \"behalf of my son arises from any fear lest he s…     2006\n 8 A Study In Scarlet \"in this terrible affair. He is utterly innocent…     2007\n 9 A Study In Scarlet \"however, that in your eyes and in the eyes of o…     2008\n10 A Study In Scarlet \"be compromised. That however is surely impossib…     2009\n# ℹ 91 more rows\n\n\nThe most remarkable thing from the sample is that each observation represents a literal line in the novel. The lines can be concatenated so that each observation is a paragraph. This will be particularly useful in understanding dialog because it is typical in literature to start a new paragraph each time a speaker changes. The NAs between lines mean we have a good boundary between paragraphs.\nAdditionally, I cross-referenced the novel order with the Canon of Sherlock Holmes in order to understand the order in which these works were published. I think it could be interesting to see if there are changes that occur between earlier works and later works.\n\nparagraphs &lt;- data |&gt;\n  mutate(paragraph = cumsum(is.na(text))) |&gt;\n  filter(!is.na(text)) |&gt;\n  group_by(book,paragraph) |&gt;\n  summarize(text = paste(text, collapse = \" \"))\n\n`summarise()` has grouped output by 'book'. You can override using the\n`.groups` argument.\n\nparagraphs_sample &lt;- paragraphs[2000:2010,]\n\nprint(paragraphs_sample)\n\n# A tibble: 11 × 3\n# Groups:   book [1]\n   book                                        paragraph text                   \n   &lt;chr&gt;                                           &lt;int&gt; &lt;chr&gt;                  \n 1 The Adventure of Charles Augustus Milverton      7455 \"\\\"What I say is true,…\n 2 The Adventure of Charles Augustus Milverton      7456 \"\\\"There you make a mi…\n 3 The Adventure of Charles Augustus Milverton      7457 \"Holmes sprang from hi…\n 4 The Adventure of Charles Augustus Milverton      7458 \"\\\"Get behind him, Wat…\n 5 The Adventure of Charles Augustus Milverton      7459 \"Milverton had glided …\n 6 The Adventure of Charles Augustus Milverton      7460 \"\\\"Mr. Holmes, Mr. Hol…\n 7 The Adventure of Charles Augustus Milverton      7461 \"Holmes sat motionless…\n 8 The Adventure of Charles Augustus Milverton      7462 \"For some days Holmes …\n 9 The Adventure of Charles Augustus Milverton      7463 \"\\\"You would not call …\n10 The Adventure of Charles Augustus Milverton      7464 \"\\\"No, indeed!\\\"\"      \n11 The Adventure of Charles Augustus Milverton      7465 \"\\\"You'll be intereste…\n\n\n\n\n\nF. Scott Fitzgerald and Earnest Hemingway were known for their very resvered use of exclamation points. Fizgerald describes it as “Laughing at your own joke.” We can use this data to determine how well Arthur Conan Doyle follows this rule.\n\nexclamation_points &lt;- paragraphs |&gt;\n  mutate(exclamation_points = str_count(text, \"!\"))\n\nexclamation_point_sample &lt;- exclamation_points |&gt;\n  filter(exclamation_points &gt; 0) |&gt;\n  slice_sample(n = 5)\n\n### showing some example lines as a sanity check to make sure our code is working\n\nprint(exclamation_point_sample)\n\n# A tibble: 240 × 4\n# Groups:   book [48]\n   book                 paragraph text                        exclamation_points\n   &lt;chr&gt;                    &lt;int&gt; &lt;chr&gt;                                    &lt;int&gt;\n 1 A Case of Identity        2195 \"\\\"Certainly,\\\" said Holme…                  1\n 2 A Case of Identity        2131 \"\\\"Ha! that was unfortunat…                  1\n 3 A Case of Identity        2197 \"\\\"Oh, it won't do--really…                  1\n 4 A Case of Identity        2207 \"\\\"There's a cold-blooded …                  1\n 5 A Case of Identity        2196 \"\\\"What! where?\\\" shouted …                  1\n 6 A Scandal in Bohemia      1847 \"\\\"What a woman--oh, what …                  1\n 7 A Scandal in Bohemia      1671 \"\\\"Pooh, pooh! Forgery.\\\"\"                   1\n 8 A Scandal in Bohemia      1754 \"\\\"Oh, the cause is excell…                  1\n 9 A Scandal in Bohemia      1829 \"\\\"Married! When?\\\"\"                         1\n10 A Scandal in Bohemia      1621 \"\\\"Quite so! You have not …                  1\n# ℹ 230 more rows\n\nexclamation_points_summary &lt;- exclamation_points |&gt;\n  group_by(book) |&gt;\n  summarize(exclamation_points = sum(exclamation_points)) |&gt;\n  left_join(books, by = \"book\") |&gt;\n  arrange(desc(exclamation_points))\n\n### actually counting exclamation points\n\nprint(exclamation_points_summary)\n\n# A tibble: 48 × 3\n   book                                        exclamation_points publish_order\n   &lt;chr&gt;                                                    &lt;int&gt;         &lt;int&gt;\n 1 The Valley Of Fear                                         319            40\n 2 The Hound of the Baskervilles                              182            39\n 3 The Sign of the Four                                       127             2\n 4 A Study In Scarlet                                          85             1\n 5 The Adventure of the Second Stain                           49            38\n 6 The Adventure of the Solitary Cyclist                       48            29\n 7 The Adventure of the Red Circle                             46            43\n 8 The Adventure of the Dying Detective                        45            45\n 9 The Adventure of the Beryl Coronet                          43            13\n10 The Adventure of the Bruce-Partington Plans                 43            44\n# ℹ 38 more rows"
  }
]